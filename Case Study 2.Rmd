---
title: "Case Study 2"
author: "Manuela Giansante & Lucia Camenisch"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true # creating a table of contents (toc)
    toc_float:
      collapsed: false # toc does not collapse and is shown as a sidebar (toc_float)
    number_sections: true # document sections are numbered
    theme: cosmo
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = "center")
```

```{r packages}
library(data.table)      # data.table type
library(tidyr)           # gather()
library(kableExtra)      # kables for html document
library(naniar)          # vis_miss()
library(corrplot)        # corrplot()
library(caret)           # findCorrelation()
library(REdaS)           # KMOS(), bart_spher()
library(psych)           # KMO(), fa(), principal()

options(scipen = 999)
# library(pastecs)
# library(dplyr)
# library(rcompanion) 
# library(GPArotation)
# library(nFactors)
# library(knitr)
```

We start by loading both data files.

```{r reading data}
descriptions <- fread("Data File_Case Study_Factor Analysis_Variables.csv")
df <- read.csv("Data File_Case_Study_Factor Analysis_MD.csv")
```

We select only the relevant columns which correspond to question numbers `qd1` to `qd33` inside `df`.

```{r selecting questions}
df1 <- df[,c(9:41)]
```

We check for missing values.

```{r missing values 1}
vis_miss(df1)
```

Since questions 22, 26, 28 and 29 contain missing values, we delete the corresponding rows.

```{r missing values 2}
df1 <- na.omit(df1)
vis_miss(df1)
```

Now, our data frame `df1` has no more missing values.


# Orthogonal Factor Analysis

## Inspect the correlation matrix.

We compute the correlation matrix and plot it.

```{r cormat}
raqMatrix <- cor(df1)
corrplot(raqMatrix, tl.cex = 0.8)
```

We can see some strong correlations, indicated by bigger and darker blue dots, between different questions.
Furthermore, we notice that `qd4` and `qd23` seem to be the only two items with low correlations with all the other items.
They are standalone items.

A strong correlation between two variables is most likely a signal of redundancy.
In regards to the correlation plot above, there are not very clear patterns, but we can observe some variables are highly correlated between one another, which is good since we want to perform a factor analysis.
More precisely, we are interested in the underlying factors causing those variables to move the way that they move.
A weaker correlation indicates that there are different factors affecting the variables, meaning they do not describe the same domain.

Listed below are the variables displaying higher correlation, with a selected threshold of 0.65.

```{r high cors loop}
n = nrow(raqMatrix)
for (i in 1:(n-1)) {
  for (j in (i+1):n) {
    if (raqMatrix[i, j] >= 0.65) {
      print(paste(colnames(df1)[i],
                  "and",
                  colnames(df1)[j],
                  "have a correlation of",
                  round(raqMatrix[i, j], 2)))
    }
  }
}

rm(i, j, n)
```

This allows us to separate the questionnaire items into clusters by grouping together variables which are highly correlated.
We can obtain exactly the same groups by using the `hclust` option when plotting the correlation matrix.
Rows and columns are swapped so items who are highly correlated can be side by side.

```{r cormat clusters}
corrplot(raqMatrix, order = 'hclust', tl.cex = 0.8, addrect = 10)
```

The clustering of the correlation matrix with 10 clusters and our grouping with threshold at 0.65 give the same results.
We get the following 10 different groups:

-   Items 1, 10, 20 and 27, all related to aesthetics;
-   Items 2, 5, 7, 12 and 16, all related to performance;
-   Items 3, 11, 13 and 30, all related to ease of use;
-   Items 6, 8, 18 and 25, all related to features;
-   Items 9, 14, 19, 21 and 24, all related to serviceability;
-   Items 15, 17 and 32, all related to quality of materials;
-   Items 22, 29 and 33, all related to flawlessness;
-   Items 26, 28 and 31, all related to durability;
-   Item 4, related to distinctiveness;
-   Item 23, related to prestige.

This grouping is quite close to quality dimensions defined in the literature (see Table 1 of the assignment pdf).
The differences would be the presence of a construct about the quality of materials, which is not listed in the dimensions of quality, and the fact that questions 4 and 23 should reflect the same underlying construct, "Distinctiveness/Prestige", but it does not seem to be the case from experimental data, as the two variables are very weekly correlated.

## Check whether the data set and all of its variables are suitable for factor analysis.

```{r histograms, eval=FALSE, include=FALSE}
# idk if we want to check all the distributions
df1[, 1:9] %>% gather() %>%                 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram() +
  theme_classic() +
  labs(title = "Histograms of questions 1 to 9")

df1[, 10:18] %>% gather() %>%                 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram() +
  theme_classic() +
  labs(title = "Histograms of questions 10 to 18")

df1[, 19:27] %>% gather() %>%                 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram() +
  theme_classic() +
  labs(title = "Histograms of questions 19 to 27")

df1[, 28:33] %>% gather() %>%                 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram() +
  theme_classic() +
  labs(title = "Histograms of questions 28 to 33")
```

To make sure that our data is suitable for Factor Analysis, we want to test to what extent our variables are correlated to one another.
To further the analysis we measure the Sampling Adequacy based on the **Kaiser-Meyer-Olking criterion**:

```{r KMO}
#Kaiser-Meyer-Olkin Statistics
KMO(df1)
```

The KMO test measures the proportion of variance between variables which can be attributed to common variance.
It takes values between 0 and 1, meaning that higher values of the test indicate that a variable is suitable for factor analysis.
The measurement is computed with the following formula: $$MO_j=\frac{\sum_{i\neq j}r^2_{ij}}{\sum_{i \neq j} r^2_{ij}+\sum_{i\neq j}p^2_{ij}}$$ where $r_{ij}$ is the correlation coefficient of the variables indexed by $i$ and $j$, and $p_{ij}$ is the partial correlation coefficient of those variables.

Our KMO mean value amounts to 0.96 which indicates that in average variables are well suited for factor analysis.
The individual MSA values of variables except for `qd4` are all above 0.9, which corresponds to "marvelous" in correspondence with Kaiser's nomenclature.
The value of `qd4` is considered as "mediocre".
We must look out for it in the next steps.

We will also take a look at the diagonal of the anti-image correlation matrix.
This gives us the proportion of a variable's variance that cannot be explained by any other variable.

```{r anti-image cormat}
# we use the KMO function from the psych package to retrieve the anti-image cor mat
anti_mat_diag = data.frame("Question" = 1:33,
                           "UniqueVar" = diag(KMO(df1)$ImCov))

ggplot(data = anti_mat_diag, aes(x = Question, y = UniqueVar)) +
  geom_col() +
  theme_classic() +
  scale_x_continuous(breaks = seq(1, 33, 1)) +
  scale_y_continuous(limits = c(0,1)) +
  labs(title = "Diagonal values of anti-image correlation matrix",
       y = "Proportion of unique variance")

rm(anti_mat_diag)
```

In our case, `qd4` and `qd23` have values above 0.5, indicating that their topics have not been sufficiently covered in the questionnaire.
They clearly result as outliers compared to all the other variables.

Another way to judge whether our data is suitable for factor analysis would be **Bartlett's test**.
The null hypothesis of this test is that the sample originates from a population, where all variables are uncorrelated, or in other words that the correlation matrix equals the identity matrix.
The test is more suited for cases in which each variable has less than 5 observations, because it is very sensitive within large samples and thus might not be a good fit for us.

The test results highly significant, meaning we can reject the null hypothesis, the data is fit for factor analysis.

```{r bartlett test}
bart_spher(df1)
```

After having considered all the above elements, this data set looks suitable for factor analysis.
The only two items we need to pay special attention to are `qd4` and `qd23`, as they might not be as well suited as the rest.

## Run principal axis factoring (PAF) and use varimax rotation.

PAF is an exploratory factor analysis method (or Factor Extraction Method), it attempts to find the least number of factors accounting for common variance of a set of variables. It uses a reduced correlation matrix, with a diagonal containing communalities.

It assumes that the variance of the observed variables cannot be fully explained by the extracted factors, it decomposes the variance in communality and unique variance, without accounting for specific and error variability.

PAF is implemented with the `fa` function from `psych` package.

We use the "varimax" rotation, which is designed to simplify the interpretation of the loadings. Varimax works by maximizing the sum of the variance of each squared factor loading. It pushes factors to become closer to 1 or 0, which facilitates interpretation.

The number of underlying factors has to be specified inside the function. If we try to input a number of factors greater than 13, `fa` returns an error. Thus, we test options for models going from 1 factor to 13 and record each time some criteria aimed at helping select the best model.

Those criterias are:

- `fit`, which measures how well the factor model reproduces the correlation matrix;
- `objective`, which is the value of the function that is minimized by a maximum likelihood procedure;
- `rms`, which is the sum of the squared off-diagonal residuals divided by the degrees of freedom;
- `crms`, which is the RMS adjusted for degrees of freedom;
- `TLI`, which is the Tucker Lewis Index of factoring reliability;
- `BIC`, which is the Bayesian information criterion.

A good model exhibits high values of `fit` and `TLI`, and low values of the others.

```{r PAF best nfactor}
# we initiate and empty dataframe which will record our criteria values
fit_df <- matrix(nrow = 13, ncol = 6)
colnames(fit_df) <- c("fit", "objective", "rms", "crms", "TLI", "BIC")
fit_df <- as.data.frame(fit_df)

# we compute the factor analysis for nfactors between 1 and 13 and record criteria results in fit_df
for (i in 1:13) {
  FA <- fa(df1, nfactors = i, rotate = "varimax", fm = "pa")
  fit_df[i, 1] <- FA$fit
  fit_df[i, 2] <- FA$objective
  fit_df[i, 3] <- FA$rms
  fit_df[i, 4] <- FA$crms
  fit_df[i, 5] <- FA$TLI
  fit_df[i, 6] <- FA$BIC
}

rm(i, FA)
```

Now, we can plot the values of each criteria with respect to the number of factors.

```{r PAF plots of criteria}
fit_df %>% gather() %>%                 
  ggplot(aes(x = rep(1:13, ncol(fit_df)), y = value)) +
  facet_wrap(~ key, scales = "free") +
  geom_point() +
  theme_classic() +
  scale_x_continuous(breaks = seq(1, 13, 1)) +
  geom_vline(xintercept = 8, linetype = "dashed") +
  geom_vline(xintercept = 9, linetype = "dashed") +
  labs(title = "Various criteria for Principal Axis Factoring",
       x = "Number of factors",
       y = "")
```

The dashed lines designate the number of factors which seem the most appropriate for our data. The improvement in criteria for numbers of factors greater than 9 is much slower and less significant. Depending on the criterion, we would choose 8 or 9, so we will test both models with and without including questions 4 and 23, since our exploratory analysis of the data indicated that those two variables probably will not be loaded onto factors, as they are standalone.


```{r PAF candidate models}
FA8 <- fa(df1, nfactors = 8, rotate = "varimax", fm = "pa")
FA8_423 <- fa(df1[, -c(4, 23)], nfactors = 8, rotate = "varimax", fm = "pa")
FA9 <- fa(df1, nfactors = 9, rotate = "varimax", fm = "pa")
FA9_423 <- fa(df1[, -c(4, 23)], nfactors = 9, rotate = "varimax", fm = "pa")
```

We examine the factor loadings of each model, using a plot similar to the correlation plot to quickly visualize them.

```{r PAF loadings viz}
par(mfrow = c(2,2))
corrplot(t(FA8$loadings),
         tl.cex = 0.7,
         title = "PAF with 8 factors \n Loadings",
         mar = c(0, 1, 3, 0))
corrplot(t(FA8_423$loadings),
         tl.cex = 0.7,
         title = "PAF with 8 factors excluding qd4 and qd23 \n Loadings",
         mar = c(0, 1, 3, 0))
corrplot(t(FA9$loadings),
         tl.cex = 0.7,
         title = "PAF with 9 factors \n Loadings",
         mar = c(0, 1, 3, 0))
corrplot(t(FA9_423$loadings),
         tl.cex = 0.7,
         title = "PAF with 9 factors excluding qd4 and qd23 \n Loadings",
         mar = c(0, 1, 3, 0))
par(mfrow = c(1,1))
```

We remark the following:

- In `FA8`, questions 4 and 23 aren't loaded on any factor. Each other variable is clearly loaded on a unique factor.
- In `FA8_423`, each variable is clearly loaded on one factor like before, since we deleted the two variables which weren't associated on any of the 8 factors. If we decide to keep a model with 8 factors, we could delete `qd4` and `qd23` as they will not be loaded onto a factor in any case.
- In `FA9`, questions 4 and 23 are loaded onto one factor together and all other variables are loaded on one of the 8 other factors. The loadings of `qd4` and `qd23` are the lowest however, at 0.414 and 0.474 respectively.
- In `FA9_423`, the ninth factor has no variable loaded on it, as we have deleted questions 4 and 23 and the other items are arranged on 8 factors. This model is not appropriate for the data and should be discarded.

In summary, there are two possible models:

- A model with 8 factors which does not include `qd4` and `qd23`;
- A model with 9 factors in which `qd4` and `qd23` are loaded onto a factor together.

We discard `FA8` and `FA9_423` and display the numerical loadings greater than 0.3 of the two remaining models.

```{r PAF loadings for 2 models}
rm(FA8, FA9_423)

print(FA8_423$loadings, cutoff = 0.3, sort = TRUE)
print(FA9$loadings, cutoff = 0.3, sort = TRUE)
```

We notice that the factors created by PAF are the same groups we identified with our clustering of the correlation matrix. In both models, `qd8`, which was grouped with the features construct, is partially loaded onto factor PA1, which corresponds to the performance construct. We fetch its description.

```{r qd8 descr}
descriptions[name %in% "qd8", ]
```
Some people answering might consider not only extra features but any features of their smartphone and evaluate their performance, i.e. how they function. This might explain why `qd8` is partially loaded onto the performance construct. However, it remains mainly loaded onto the features construct, with a value of 0.558 or 0.559 according to the model.

In model `FA9`, loadings of `qd4` and `qd23` on their factor are the weakest of all "main" loadings. This could indicate that keeping `qd4` and `qd23` might not be totally appropriate and is up to discussion.

When looking at the communalities of our models, we get the following results:

```{r PAF communalities}
sort(FA8_423$communality)
sort(FA9$communality)
```

This further indicates that questions 4 and 23 might not be appropriate in for factor analysis, as their communalities inside `FA9` are extremely low. The communality of an item is the sum of the squared factor loadings for that item. It measures the proportion of the item's variance that can be explained by the underlying factors. If the communality equals 1 then a complete replication of the variable can me obtained through the sole use of factors.

We observe the scree plots of our two models.

```{r PAF scree plots}
ggplot(mapping = aes(x = 1:length(FA8_423$values),
                     y = FA8_423$values,
                     color = (FA8_423$values >= 1))) +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  theme_classic() +
  labs(title = "Scree plot of FA8_423",
       x = "Factor Number",
       y = "Eigenvalue",
       color = "Eigenvalue >= 1")

ggplot(mapping = aes(x = 1:length(FA9$values),
                     y = FA9$values,
                     color = (FA9$values >= 1))) +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  theme_classic() +
  labs(title = "Scree plot of FA9",
       x = "Factor Number",
       y = "Eigenvalue",
       color = "Eigenvalue >= 1")
```

The eigenvalues are plotted above, the horizontal line represents the significance threshold of 1. If we would only select based on the eigenvalues bigger than 1, then our model would have only 5 factors. However, due to all our previous analysis, this does not seem to be the best choice. The elbow rule would probably cut at 8 factors for `FA8_423`, as there is a bigger gap between 8 and 9. However, `FA9` does not have such a gap and the descent is quite smooth, so it is more difficult to determine.


## Decide on a final principal factor analysis solution.

After reviewing all the information we gathered about our model, we decide to keep `FA8_423` over `FA9`.

Questions 4 and 23 Showed very little correlation with each other and even if they should theoretically represent the same construct of distinctiveness and prestige, the construct was not explored enough through questions in the survey. Every other construct had between 3 and 5 questions and the questions exhibit high correlations when they are in the same group.

Furthermore, the BIC is lowest for 8 factors and starts slowly rising again once we get past 8. The loadings of `qd4` and `qd23` in the `FA9` model remain lower than all other loadings of items inside their construct, being even lower than 0.5. When we looked at the anti-image correlation matrix diagonal, the proportions of unique variance in questions 4 and 23 were dominating the rest, indicating that the rest of the data set cannot explain most of their variance. Moreoever, their communalities were very low in `FA9`.

These reasons combined made us choose model `FA8_423`. Its constructs are the ones we listed when we inspected the correlation matrix (except of course the constructs of questions 4 and 23). The loading patterns of `FA8_423`, as we discussed in the previous point, are clear.


## Run a principal component analysis (PCA) and compare the results.

Like with PAF, we run models with number of components ranging from 1 to 33 and will examine some criteria to get an idea of which ones best fit our data.

For PCA, the criteria are:

- `fit`, which measures how well the components model reproduces the correlation matrix;
- `fit.off`, which measures how well the off-diagonal elements of the correlation matrix are reproduced;
- `objective`, which is the value of the function that is minimized by a maximum likelihood procedure;
- `rms`, which is the sum of the squared off-diagonal residuals divided by the degrees of freedom.


```{r PCA best nfactor}
# we initiate and empty dataframe which will record our criteria values
fit_df <- matrix(nrow = 33, ncol = 4)
colnames(fit_df) <- c("fit", "fit.off", "objective", "rms")
fit_df <- as.data.frame(fit_df)

# we compute the PCA for nfactors between 1 and 33 and record criteria results in fit_df
for (i in 1:33) {
  PCA <- principal(df1, nfactors = i, rotate = "varimax")
  fit_df[i, 1] <- PCA$fit
  fit_df[i, 2] <- PCA$fit.off
  fit_df[i, 3] <- PCA$objective
  fit_df[i, 4] <- PCA$rms
}

rm(i, PCA)
```

We plot the results like before.

```{r PCA plots of criteria}
fit_df %>% gather() %>%                 
  ggplot(aes(x = rep(1:33, ncol(fit_df)), y = value)) +
  facet_wrap(~ key, scales = "free") +
  geom_point() +
  theme_classic() +
  scale_x_continuous(breaks = seq(1, 33, 2)) +
  geom_vline(xintercept = 10, linetype = "dashed") +
  labs(title = "Various criteria for Principal Component Analysis",
       x = "Number of components",
       y = "")
```

Here, the ideal number of components seems to be 10, indicated by a dashed line. It is a local minimum of the objective function and is at thw elbow of the other three curves.

However, we check if this result would vary by omitting standalone variables `qd4` and `qd23`.

```{r PCA best nfactor 423}
# we initiate and empty dataframe which will record our criteria values
fit_df <- matrix(nrow = 31, ncol = 4)
colnames(fit_df) <- c("fit", "fit.off", "objective", "rms")
fit_df <- as.data.frame(fit_df)

# we compute the PCA for nfactors between 1 and 31 and record criteria results in fit_df
for (i in 1:31) {
  PCA <- principal(df1[, -c(4,23)], nfactors = i, rotate = "varimax")
  fit_df[i, 1] <- PCA$fit
  fit_df[i, 2] <- PCA$fit.off
  fit_df[i, 3] <- PCA$objective
  fit_df[i, 4] <- PCA$rms
}

rm(i, PCA)
```

Again, we plot the evolution of the criteria.

```{r PCA plots of criteria 423}
fit_df %>% gather() %>%                 
  ggplot(aes(x = rep(1:31, ncol(fit_df)), y = value)) +
  facet_wrap(~ key, scales = "free") +
  geom_point() +
  theme_classic() +
  scale_x_continuous(breaks = seq(1, 31, 2)) +
  geom_vline(xintercept = 8, linetype = "dashed") +
  labs(title = "Various criteria for Principal Component Analysis without qd4 and qd23",
       x = "Number of components",
       y = "")
```

Without questions 4 and 23, the best model seems to be the one with 8 components.

Thus, we will test these three models.

```{r PCA models}
PCA8 <- principal(df1, nfactors=8, rotate = "varimax")
PCA8_423 <- principal(df1[, -c(4, 23)], nfactors = 8, rotate = "varimax")
PCA10 <- principal(df1, nfactors = 10, rotate = "varimax")
```

We examine the factor loadings, first by plotting them.

```{r PCA loadings viz}
par(mfrow = c(2,1))
corrplot(t(PCA8$loadings),
         tl.cex = 0.7,
         title="CPA with 8 factors including qd4 and dq23 \n Loadings",
         mar = c(1, 1, 3, 0))
corrplot(t(PCA8_423$loadings),
         tl.cex = 0.7,
         title = "CPA with 8 factors excluding qd4 and qd23 \n Loadings",
         mar = c(1, 1, 3, 0))
par(mfrow = c(1,1))
corrplot(t(PCA10$loadings),
         t.cex = 0.7,
         title = "CPA with 10 factors \n Loadings",
         mar = c(1, 1, 3, 0))
```
In both `PCA8_423` and `PCA10`, each questions looks strongly loaded onto one component. In `PCA8_423`, question 4 and 23 each have their own component and their loadings are the strongest ones, in opposition to what we observed for PAF.

However, `PCA8` has some less clearer loadings, in particular when looking at factor `RC7`. The two groups we had defined as durability and quality of materials are pushed together onto one component, but the loadings given to durability are smaller than when they are allowed to be by themselves onto one component like in `PCA8_423`.

We take a look at the numerical values of the loadings, displaying only the ones above 0.3.

```{r PCA loadings}
print(PCA8$loadings, cutoff = 0.3, sort=TRUE)
print(PCA8_423$loadings, cutoff = 0.3, sort = TRUE)
print(PCA10$loadings, cutoff = 0.3, sort = TRUE)
```


Like with PAF, we notice that `qd8` is partially loaded onto the component corresponding to performance. However, compared with PAF, the loadings are globally slightly higher. The loadings of questions 4 and 23 are extremely high for `PCA10`.

The loadings for `PCA8` have a lot of variables with low loadings, which does not seem to be the best option, given that comparatively the other models look much nicer.

We take a look at the communalities.

```{r PCA communalities}
sort(PCA8$communality)
sort(PCA8_423$communality)
sort(PCA10$communality)
```

Unlike with PAF, in `PCA10`, the underlying components in our model, which are dedicated to `qd4` and `qd23`, explain most of the variance of the two variables. This gives both models high communalities for all variables, with the lowest values being around 0.73.

The communalities for `PCA8` are lower for many of the variables, observing this and the unclear loadings, we decide to not move further with this model.

```{r removing PCA8}
rm(PCA8)
```


We display the scree plots.

```{r PCA scree plots}
ggplot(mapping = aes(x = 1:length(PCA8_423$values),
                     y = PCA8_423$values,
                     color = (PCA8_423$values >= 1))) +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  theme_classic() +
  labs(title = "Scree plot of PCA8_423",
       x = "Component Number",
       y = "Eigenvalue",
       color = "Eigenvalue >= 1")

ggplot(mapping = aes(x = 1:length(PCA10$values),
                     y = PCA10$values,
                     color = (PCA10$values >= 1))) +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  theme_classic() +
  labs(title = "Scree plot of PCA10",
       x = "Component Number",
       y = "Eigenvalue",
       color = "Eigenvalue >= 1")
```

Again, the rule of taking values above 1 seems slightly more strict than what our analysis seems to indicate. However, both models have a small but distinct elbow, which corresponds to the number of components selected for each.

We take a look at the the total variance explained by each component in our models.

Let us recall that the eigenvalue of a component represents the amount of the total variance explained (TVE) by that component. We can directly fetch these numbers inside our models.

```{r vaccounted pca8}
PCA8_423$Vaccounted
```


```{r eval=FALSE, include=FALSE}
TVE_PCA8_423 <- data.frame("Cmpt_num" = 1:sum(PCA8_423$values),
                           "Eigenvalue" = PCA8_423$values,
                           "TVE_prop" = PCA8_423$values / sum(PCA8_423$values) * 100,
                           "TVE_cumprop" = cumsum(PCA8_423$values / sum(PCA8_423$values) * 100))

kable(TVE_PCA8_423, col.names = c("Component",
                                  "Eigenvalue",
                                  "Percentage of TVE",
                                  "Cumulative percentage of TVE"), digits = 2) %>%
   kable_styling(full_width = TRUE)
```

Thus, with 8 factors the percentage of the total variance which is explained by the model is 84.11%. 

```{r vaccounted pca10}
PCA10$Vaccounted
```

```{r eval=FALSE, include=FALSE}
TVE_PCA10 <- data.frame("Cmpt_num" = 1:sum(PCA10$values),
                        "Eigenvalue" = PCA10$values,
                        "TVE_prop" = PCA10$values / sum(PCA10$values) * 100,
                        "TVE_cumprop" = cumsum(PCA10$values / sum(PCA10$values) * 100))

kable(TVE_PCA10, col.names = c("Component",
                               "Eigenvalue",
                               "Percentage of TVE",
                               "Cumulative percentage of TVE"), digits = 2) %>%
   kable_styling(full_width = TRUE)

rm(TVE_PCA10, TVE_PCA8_423)
```

Thus, with 10 factors the percentage of the total variance which is explained by the model is 85.15%.

Both results are quite close and our factors explain most of the variance in the data. **eigenvalue ?**

To be coherent with the best model we chose for PAF, we will select `PCA8_423`. `PCA10` works well from the point of view of principal component analysis, because its goal is to produce an empirical summary of the data set. However, the components of PCA do not necessarily have a causal interpretation, in opposition to PFA, which aims find underlying constructs of the data, called factors. Since our PFA analysis showed that `qd4` and `qd23` are not adapted to this modelling via factors because of their standalone nature, to preserve the most meaningful interpretation of our data set, we will continue by keeping `FA8_423` and `PCA8_423`.

```{r removing FA9 and PCA10}
rm(FA9, PCA10)
```


## What do the eigenvalues of the factors (quality dimensions) tell us about their relevance for repurchase behaviour?

As we saw previously, both `FA8_423` and `PCA8_423` have showed clear loading patterns. We now look at the TVE tables again to gain more insight on how the eigenvalues (which are the sum of squared loadings by factor or component) describe the portion of each factor or component.


```{r eigenvalues and importance}
TVE_PAF <- FA8_423$Vaccounted
TVE_PCA <- PCA8_423$Vaccounted

# we rename each factor or component to designate the quality dimensions we have established
colnames(TVE_PAF) <- c("Serviceability", "Performance", "Aesthetics", "Ease of use",
                       "Flawlessness", "Features", "Quality of materials", "Durability")
colnames(TVE_PCA) <- c("Serviceability", "Performance", "Aesthetics", "Ease of use",
                       "Features", "Flawlessness", "Quality of materials", "Durability")

TVE_PAF %>% kable(digits = 3) %>% kable_styling(full_width = TRUE)
TVE_PCA %>% kable(digits = 3) %>% kable_styling(full_width = TRUE)
```

In both PAF and PCA, the top three factors or components explaining the bigger proportions of variance are Serviceability, Performance and Aesthetics. The only change of order between factors is Features and Flawlessness which switch places between the two models. To better visualize the repartition of explained variance among factors, we display two Pareto charts.

```{r pareto chart PAF}
ggplot(mapping = aes(x = reorder(colnames(TVE_PAF), -TVE_PAF[4,]), y = TVE_PAF[4,])) +
  geom_col() +
  geom_line(aes(x = 1:8, y = TVE_PAF[5,]), color = "red") +
  geom_point(aes(x = 1:8, y = TVE_PAF[5,])) +
  theme_classic() +
  labs(x = "Factor",
       y = "Proportion of TVE",
       title = "Pareto chart of TVE for FA8_423")
```

```{r pareto chart PCA}
ggplot(mapping = aes(x = reorder(colnames(TVE_PCA), -TVE_PCA[4,]), y = TVE_PCA[4,])) +
  geom_col() +
  geom_line(aes(x = 1:8, y = TVE_PCA[5,]), color = "red") +
  geom_point(aes(x = 1:8, y = TVE_PCA[5,])) +
  theme_classic() +
  labs(x = "Component",
       y = "Proportion of TVE",
       title = "Pareto chart of TVE for PCA8_423")
```

In both cases, Serviceability is the dimension which is more important, with the biggest gap compared to other dimensions. The Pareto curve is very smooth and flat, which means that the importance of each dimension is a slow decrease. This can also be observed by the fact that gaps are minimal between each bar once we pass Serviceability. This means that even if there are some more important dimensions, all dimensions bring their share in explaining part of the TVE, there does not seem to be a superfluous or unimportant dimension.



# Oblique Factor Analysis

## Run an oblique factor analysis with the variables of your final solution in exercise 1 using Promax.

We run the OFA with principal axis factoring like before. What changes is the rotation method, which is not orthogonal anymore but accounts for correlations between factors (thus the term oblique).

```{r OFA8_423}
OFA8_423 <- fa(df1[, -c(4, 23)], nfactors = 8, rotate = "promax", fm = "pa")
```

## How high are the factors correlated and what is the highest correlation between factors?

We display a correlation plot of the Phi matrix.

```{r}
cor_fac <- OFA8_423$Phi

# changing to names of constructs for interpretability

colnames(cor_fac) <- c("Serviceability", "Performance", "Aesthetics", "Ease of use",
                       "Features", "Quality of materials", "Flawlessness", "Durability")

rownames(cor_fac) <- c("Serviceability", "Performance", "Aesthetics", "Ease of use",
                       "Features", "Quality of materials", "Flawlessness", "Durability")

corrplot(cor_fac)
```

The highest correlation is between Performance and Features at 0.72. Both factors are quite close, as the performance of a smartphone can be linked to the performance of the features of said smartphone, and conversely one can think about the performance of a particular extra feature. The two topics having some overlap, as we also saw for example in past models with `qd8` being partially loaded onto the Performance construct, it is not surprising that they are quite strongly correlated.

The lowest correlation is between Serviceability and Flawlessness, at 0.40. This also seems logical, as the relationship between customer service and the defects or glitches of a smartphone is quite removed, we would expect them not to be strongly correlated.

We display a boxplot of the values of the correlations between factors (except for the diagonal values which are always 1).

```{r}
cor_fac <- cor_fac * upper.tri(cor_fac)
cor_fac <- c(cor_fac)
cor_fac <- cor_fac[cor_fac != 0]

ggplot(mapping = aes(y = cor_fac)) +
  geom_boxplot(width = 0.6) +
  theme_classic() +
  scale_x_continuous(limits = c(-0.5,0.5)) +
  theme(axis.ticks.x = element_blank(), axis.text.x = element_blank()) +
  labs(y = "Correlation values",
       title = "Boxplot of correlations between factors for OFA8_423")
```

Correlations between distinct factors range, as we saw, between 0.4 and 0.7. The median is around 0.55, with half the values being roughly between 0.51 and 0.61. This shows that correlations between factors are quite strong. Orthogonal factor analysis done in exercise 1 might not have been the best model to describe the factors, as correlations are significant.

## Compute factor scores for your factors and name and label them appropriately.

We can fetch the factor scores directly inside our model. We rename the columns as we did with the correlation matrix before and display the first six rows of our factor scores.

```{r}
factors <- as.data.frame(OFA8_423$scores)

colnames(factors) <- c("Serviceability", "Performance", "Aesthetics", "Ease of use",
                       "Features", "Quality of materials", "Flawlessness", "Durability")

head(factors) %>% kable(digits = 2) %>% kable_styling(full_width = TRUE)
```

## Compute mean scores for the three willingness to pay premium items `wtp1`, `wtp2`, `wtp3` and the two repurchase intention items `ri1`, `ri2`.

We create a dataframe selecting all columns which will be useful for the rest of this exercise. We remove NA values from the dataframe.

```{r}
dfobl <- df[, c(9:41, 43,44,45, 51,52, 74)]
dfobl <- na.omit(dfobl)
```

We use factor analysis to construct two factors from the five variables mentioned.

```{r}
y_factor_model <- fa(dfobl[, 35:39], nfactors = 2, rotate = "promax", fm = "pa")
y_factor_model$loadings
y_factor_model$Phi
```

```{r}
dfreg <- cbind(factors, y_factor_model$scores, df1$qd4, df1$qd23)
colnames(dfreg)[9:12] <- c("wtp", "ri", "qd4", "qd23")
dfreg <- scale(dfreg)
dfreg <- as.data.frame(dfreg)
```


## Run a regression analysis with the factor scores of the quality dimensions as independent and both the mean score of willingness to pay premium and repurchase intention as dependent variables.




```{r}
lmreg <- lm(wtp ~. , data = dfreg[, -c(10,11,12)])
summary(lmreg)
```


```{r}
lmreg <- lm(wtp ~. , data = dfreg[, -10])
summary(lmreg)
```

```{r}
lmreg <- lm(ri ~. , data = dfreg[, -c(9,11,12)])
summary(lmreg)
```

```{r}
lmreg <- lm(ri ~. , data = dfreg[, -9])
summary(lmreg)
```

## Do the results of the regression analysis for repurchase intentions differ across brands?

```{r}
dfreg$brandrec <- as.factor(dfobl$brandrec)
levels(dfreg$brandrec) <- c("Apple", "Samsung", "LG", "Motorola", "Other")

ggplot(data = dfreg, aes(brandrec)) +
  geom_bar() +
  theme_classic() +
  labs(title = "Repartition of brands in dataset",
       x = "Brand",
       y = "Count")

summary(dfreg$brandrec)
```


```{r}
lmreg <- lm(wtp ~. , data = dfreg[dfreg$brandrec == "Apple", -c(10,13)])
summary(lmreg)
```
```{r}
lmreg <- lm(ri ~. , data = dfreg[dfreg$brandrec == "Motorola", -c(9,13)])
summary(lmreg)
```






